{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e90e074-ff82-4312-9ca8-4d74ca19e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd75471-8c76-423f-917d-724065463670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readJSON(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        try:\n",
    "            g = d['gameID']\n",
    "        except Exception as e:\n",
    "            g = None\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bca0b7-b08c-482f-8022-40e2c8587177",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-play baseline: just rank which games are popular and which are not, and return '1' if a game is among the top-ranked\n",
    "\n",
    "def baseline(ugPairs_train,threshold=.5):\n",
    "    gameCount = defaultdict(int)\n",
    "    totalPlayed = 0\n",
    "    \n",
    "    for user,game in ugPairs_train:\n",
    "        gameCount[game] += 1\n",
    "        totalPlayed += 1\n",
    "        \n",
    "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse() \n",
    "    \n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalPlayed*threshold: break\n",
    "            \n",
    "    def predict(ugPairs_test):\n",
    "        pred = []\n",
    "        for u,g in ugPairs_test:\n",
    "            pred.append(1 if g in return1 else 0)\n",
    "        return pred\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cece1af-3c24-4db7-97ac-00fce5730c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTestPredictions(predict):\n",
    "    predFile = open(\"predictions_Played.txt\", 'w')\n",
    "    os.remove(\"predictions_Played.txt\")\n",
    "    predFile = open(\"predictions_Played.txt\", 'w')\n",
    "    for l in open(\"pairs_Played.txt\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predFile.write(l)\n",
    "            continue\n",
    "        u,g = l.strip().split('-')\n",
    "        predFile.write(u+'-'+g+\",\"+str(predict([(u,g)])[0])+\"\\n\")\n",
    "    predFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68229c21-f285-41a6-9007-d229ff230589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e56ced-c355-4b34-9cdd-d13fa74a6a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Play Prediction \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Play Prediction\n",
    "print(\"\\n Play Prediction \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5b3d37-1a81-46bd-af68-c437ebd6b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data (‘train.json.gz’) as follows:\n",
    "# (1) Reviews 1-165,000 for training\n",
    "# (2) Reviews 165,001-175,000 for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b4e85d-1cef-41a5-9c31-cf72a2add007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ugPairs = []\n",
    "timePlayed = []\n",
    "    \n",
    "for u,g,d in readJSON(\"train.json.gz\"):\n",
    "    ugPairs.append((u,g))\n",
    "    timePlayed.append(d[\"hours_transformed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def32fc0-2c57-483d-b73d-1a2b8703f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test baseline\n",
    "# writeTestPredictions(baseline(ugPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e87e-177a-44ee-b9fb-7a871c515692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4ff706-d774-41fe-a933-db90774e9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ugPairs_training = ugPairs[0:165000]\n",
    "hasPlayed_training = [1] * len(ugPairs_training)\n",
    "timePlayed_training = timePlayed[0:165000]\n",
    "\n",
    "ugPairs_validation = ugPairs[165000:175000]\n",
    "hasPlayed_validation = [1] * len(ugPairs_validation)\n",
    "timePlayed_validation = timePlayed[165000:175000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce9e19b-0caf-48ca-a0ef-5c90f6c58bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each entry (user,game) in the validation set, \n",
    "# sample a negative entry by randomly choosing a game that user hasn’t played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "181c723d-cd10-45b4-972c-8b6fb0d42d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamesByUser = defaultdict(set)\n",
    "usersByGame = defaultdict(set)\n",
    "gameCount = defaultdict(int)\n",
    "totalPlayed = 0\n",
    "timePlayedByUserGame = defaultdict(lambda:0)\n",
    "\n",
    "for i,(user,game) in enumerate(ugPairs_training):\n",
    "    gamesByUser[user].add(game)\n",
    "    usersByGame[game].add(user)\n",
    "    gameCount[game] += 1\n",
    "    totalPlayed += 1\n",
    "    timePlayedByUserGame[(user,game)] = timePlayed[i]\n",
    "    \n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26c70ff7-09a8-4527-888b-c9293e996fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = list(usersByGame.keys())\n",
    "newValidationEntries = []\n",
    "newHasPlayedEntries = []\n",
    "\n",
    "for u,g in ugPairs_validation:\n",
    "    randomGame = random.choice(games)\n",
    "    while u in usersByGame[randomGame]:\n",
    "        randomGame = random.choice(games)\n",
    "    newValidationEntries.append([u,randomGame])\n",
    "    newHasPlayedEntries.append(0)\n",
    "\n",
    "ugPairs_validation.extend(newValidationEntries)\n",
    "hasPlayed_validation.extend(newHasPlayedEntries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be825e1c-85fd-4d58-910f-d5552174847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,y):\n",
    "    return sum([p==y[i] for i,p in enumerate(pred)])/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ceaf7ed-53b9-4f75-a926-44a899019e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 1 \n",
      "\n",
      "Accuracy of baseline with 50 percentile performance:\n",
      "0.6819\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "print(\"\\n Question 1 \\n\")\n",
    "# accuracy of the baseline model on the validation set you have built (1 mark).\n",
    "predictions = baseline(ugPairs_training)(ugPairs_validation)\n",
    "print(\"Accuracy of baseline with 50 percentile performance:\")\n",
    "print(accuracy(predictions,hasPlayed_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e50fd35-5992-4b83-9401-232a845e3bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 2 \n",
      "\n",
      "Accuracy with threshold of .65\n",
      "0.70255\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print(\"\\n Question 2 \\n\")\n",
    "\n",
    "#baseline - using a threshold of the 50th percentile of popularity (totalPlayed/2).\n",
    "#find a better threshold and report its performance on your validation set\n",
    "\n",
    "predictions = baseline(ugPairs_training,.65)(ugPairs_validation) \n",
    "print(\"Accuracy with threshold of .65\") \n",
    "print(accuracy(predictions,hasPlayed_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "304f346c-7c5d-434e-9df9-ddc40e9c9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 3 \n",
      "\n",
      "Accuracy with sim threshold of .16:\n",
      "0.67315\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "\n",
    "# Given a pair (u, g) in the validation set, consider all training items g′ that user u has played. \n",
    "# For each, compute the Jaccard similarity between g and g′, i.e., users (in the training set) who have played g and users who have played g′. \n",
    "\n",
    "# Predict as ‘played’ if the maximum of these Jaccard similarities exceeds a threshold\n",
    "# Report the performance on your validation set\n",
    "def JaccardSim(g1, g2):\n",
    "    n = len(g1.intersection(g2))\n",
    "    d = len(g1.union(g2))\n",
    "    return n / d\n",
    "\n",
    "def Q3predict(ugPairs_test, threshold = .031):\n",
    "    pred = []\n",
    "    for u,g in ugPairs_test:\n",
    "        sims = []\n",
    "        for g2 in gamesByUser[u]:\n",
    "            if g2 == g: continue\n",
    "            sims.append(JaccardSim(usersByGame[g], usersByGame[g2]))\n",
    "        maximum = max(sims) if len(sims)>0 else None\n",
    "        pred.append(1 if maximum != None and maximum>threshold else 0)\n",
    "    return pred\n",
    "\n",
    "\n",
    "print(\"\\n Question 3 \\n\")\n",
    "\n",
    "predictions = Q3predict(ugPairs_validation)\n",
    "print(\"Accuracy with sim threshold of .16:\")\n",
    "print(accuracy(predictions,hasPlayed_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030bf63e-45ec-4baa-b92d-e066b6ff64ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e427f071-0ded-48f5-aed2-7bf3d6815809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 4 \n",
      "\n",
      "Accuracy with a similarity threshold of .7 and a popularity threshold of .021:\n",
      "0.703\n"
     ]
    }
   ],
   "source": [
    "# 4 \n",
    "\n",
    "# Improve using both a Jaccard-based threshold and a popularity based threshold.\n",
    "# Report the performance on your validation set\n",
    "\n",
    "\n",
    "def Q4predict(ugPairs_test):\n",
    "    popPredict = baseline(ugPairs_training,.70)(ugPairs_test) \n",
    "    simPredict = Q3predict(ugPairs_test,.021)\n",
    "    predict = []\n",
    "    for i in range(len(popPredict)):\n",
    "        predict.append(1 if popPredict[i]==1 and simPredict[i]==1 else 0)\n",
    "    return predict\n",
    "        \n",
    "\n",
    "print(\"\\n Question 4 \\n\")\n",
    "\n",
    "predictions = Q4predict(ugPairs_validation)\n",
    "print(\"Accuracy with a similarity threshold of .7 and a popularity threshold of .021:\")\n",
    "print(accuracy(predictions,hasPlayed_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b606a0b6-1771-4300-bba1-d53eb1fc52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 \n",
    "\n",
    "# run our model on the test set, ‘pairs Played.txt’, run #4 model and upload your solution to Kaggle.\n",
    "writeTestPredictions(Q4predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547060a-ce2c-40fc-bf39-0fa4789aa9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Insert Kaggle Performance Here\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac4f8a-3db2-4f05-97ec-7a28e1e0b93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47f58aa6-d14e-469d-b201-622970342371",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "######### Time Played Prediction ###############\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac8b9d28-10eb-434b-b66b-aa2d9632dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time Played Prediction \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Played Prediction\n",
    "print(\"\\n Time Played Prediction \\n\")\n",
    "\n",
    "# use part of the data for validation\n",
    "# the time transformed field, which is computed as log2(time played + 1).\n",
    "# This is the quantity we are trying to predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f173838-95be-4c74-8862-2bb3152dba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "print(\"\\n Question 9 \\n\")\n",
    "\n",
    "# Fit a predictor of the form: time(user,item) = mean + BiasTerm_User + BiasTerm_Item\n",
    "# ... as described in the lecture notes.\n",
    "# Use a regularization parameter of λ = 1.\n",
    "\n",
    "# Report the MSE on the validation set\n",
    "\n",
    "timePlayedByUserGame_Validation = defaultdict(lambda:0)\n",
    "ugPairs_validation_time = ugPairs_validation[:1000]\n",
    "\n",
    "for i,(user,game) in enumerate(ugPairs_validation_time):\n",
    "    timePlayedByUserGame_Validation[(user,game)] = timePlayed_validation[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3542e64-9301-4cb8-a6f9-585dd8a377c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10836021.48241849\n",
      "13271921.94879321\n",
      "12982270.950644014\n",
      "12977661.500099069\n",
      "12980167.140861055\n"
     ]
    }
   ],
   "source": [
    "#random initialization\n",
    "alpha={}\n",
    "alpha[1] = 1.0*sum(timePlayed_validation)/len(timePlayed_validation)\n",
    "BiasUser = defaultdict(lambda:0)\n",
    "BiasGame = defaultdict(lambda:0)\n",
    "\n",
    "\n",
    "def updateAlpha(l):\n",
    "    alpha[1] = sum([timePlayedByUserGame[(u,g)] - BiasUser[u]-BiasGame[g] for u,g in ugPairs_training])/len(ugPairs_training)\n",
    "    \n",
    "def updateBiasUser(u,l):\n",
    "    BiasUser[u] = sum([timePlayedByUserGame[(u,g)] - alpha[1]-BiasGame[g] for g in gamesByUser[u]]) / (l + len(gamesByUser[u]))\n",
    "    \n",
    "def updateBiasGame(g,l):\n",
    "    BiasGame[g] = sum([timePlayedByUserGame[(u,g)] - alpha[1]-BiasUser[u] for u in usersByGame[g]]) / (l + len(usersByGame[g]))\n",
    "    \n",
    "def printObjectiveFunc(l):\n",
    "    print(sum([(alpha[1]+BiasUser[u]+BiasGame[i]-timePlayedByUserGame[(u,g)])**2 for u,g in ugPairs_training])+l*(sum([BiasUser[u]**2 for u in BiasUser])+sum([BiasGame[g2]**2 for g2 in BiasGame])**2))\n",
    "\n",
    "def update(l,i):\n",
    "    updateAlpha(l)\n",
    "    [updateBiasUser(u,l) for u in gamesByUser]\n",
    "    [updateBiasGame(g,l) for g in usersByGame]\n",
    "    if i % 100 ==0:\n",
    "        printObjectiveFunc(l)\n",
    "    \n",
    "\n",
    "for i in range(500):\n",
    "    update(1,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f96ad36-5a8e-4014-b4c1-e73674f69e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:\n",
      "5.596353081460636\n"
     ]
    }
   ],
   "source": [
    "MSE = sum([(timePlayedByUserGame_Validation[(u,g)]-(alpha[1]+BiasUser[u]+BiasGame[i]))**2 for u,g in ugPairs_validation_time])/len(ugPairs_validation_time)\n",
    "print(\"MSE:\")\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "819bcbe1-7b3a-46d0-9af4-f751182b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 10 \n",
      "\n",
      "The user with the max value of the Bias is:\n",
      "u38845867\n",
      "The game with the max value of the Bias is:\n",
      "u38845867\n",
      "The user with the min value of the Bias is:\n",
      "b05546112\n",
      "The game with the min value of the Bias is:\n",
      "b05546112\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "print(\"\\n Question 10 \\n\")\n",
    "import operator\n",
    "# Report the user and game IDs that have the largest and smallest values of β\n",
    "print(\"The user with the max value of the Bias is:\")\n",
    "print(max(BiasUser.items(), key=operator.itemgetter(1))[0])\n",
    "print(\"The game with the max value of the Bias is:\")\n",
    "print(max(BiasUser.items(), key=operator.itemgetter(1))[0])\n",
    "print(\"The user with the min value of the Bias is:\")\n",
    "print(min(BiasGame.items(), key=operator.itemgetter(1))[0])\n",
    "print(\"The game with the min value of the Bias is:\")\n",
    "print(min(BiasGame.items(), key=operator.itemgetter(1))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17822a56-2271-45a4-8e2e-9c1cb759138e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3505958e-54a4-4ece-861a-df04fa55984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question 11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11\n",
    "print(\"\\n Question 11 \\n\")\n",
    "\n",
    "# Find a better value of λ using your validation set.\n",
    "\n",
    "#Report the value you chose, its MSE, and upload your solution to Kaggle by running it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6d1593b-00fb-4c8b-8ec3-e4fc707f69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6044215.035878684\n",
      "8045924.964042197\n",
      "7435117.836161754\n",
      "7307944.148052311\n",
      "7284373.81738448\n",
      "using a lambda of 0.5\n",
      "MSE:\n",
      "5.588154240117794\n"
     ]
    }
   ],
   "source": [
    "l = .5\n",
    "\n",
    "#random initialization\n",
    "alpha={}\n",
    "alpha[1] = 1.0*sum(timePlayed_validation)/len(timePlayed_validation)\n",
    "BiasUser = defaultdict(lambda:0)\n",
    "BiasGame = defaultdict(lambda:0)\n",
    "\n",
    "for i in range(500):\n",
    "    update(l,i)\n",
    "    \n",
    "print(\"using a lambda of \"+str(l))\n",
    "MSE = sum([(timePlayedByUserGame_Validation[(u,g)]-(alpha[1]+BiasUser[u]+BiasGame[i]))**2 for u,g in ugPairs_validation_time])/len(ugPairs_validation_time)\n",
    "print(\"MSE:\")\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d7b2e78-5e0c-442b-b1f3-b65a2f6ba4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictHours(u,g):\n",
    "    return alpha[1] + BiasUser[u] + BiasGame[g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4332c850-7641-42a4-8e54-88c180331fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predFile = open(\"predictions_Hours.txt\", 'w')\n",
    "os.remove(\"predictions_Hours.txt\")\n",
    "predFile = open(\"predictions_Hours.txt\", 'w')\n",
    "for l in open(\"pairs_Hours.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predFile.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split('-')\n",
    "    predFile.write(u+'-'+g+\",\"+str(predictHours(u,g))+\"\\n\")\n",
    "predFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410b117-6cf7-43f0-8797-b94552781218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397a945-38f5-4027-8d3d-08678253d476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
